ATOMIC 연산 (Atomic Operation)
============

이번에 정리할 내용은 Atomic 연산(Atomic Operation)에 대한 내용입니다. 

SW를 싱글 쓰레드로만 구현한 경우에는 신경을 쓸 부분이 아니지만, 멀티쓰레드로 SW를 구현하는 경우에는 락 (Mutex, SpinLock 등) 만큼 중요한 것이 이번에 설명할 atomic 연산이라고 할 수 있습니다.

일단 왜 Atomic 연산이 멀티쓰레드에서 중요한 것인지를 이해하기 위해서는 CPU에서 SW의 연산에 사용되는 데이타가 어떻게 관리되는지를 먼저 이해할 필요가 있습니다.  

CPU의 데이타 관리 구조 (레지스터 / 캐시 / 메모리) 
--------

우리가 작성한 SW는 일반적으로 영구 저장 장치 (HDD, Flash 등)에 저장되어 있으며, SW의 수행이 필요한 시점에 주 메모리 (DDR, SDRAM, SRAM 등)에 로딩되며 SW에 의해 연산/생성/참조되는 데이타들 역시 기본적으로는 모두 주 메모리안에 저장된다는 된다는 것은 알고 계실 겁니다.

어셈블러를 구현하지 않는 이상 일반적인 SW를 구현하는 프로그래머에게 저장 공간은 주 메모리 (또는 디스크등) 만 보이지만 CPU와 주 메모리 사이에는 아래와 같이 추가적인 데이타 저장 공간이 존재하고 있습니다. 

| 종류      | 억세스 속도        | 용량            
| :------- | :----              | :--
| Register | 제일 빠름          |  ~ 수백 바이트  
| L1 Cache | Register 보다 느림 |  Register 보다 많음 (~ 수십 KB)       
| L2 Cache | L1 Cache보다 느림  |  L1 Cache 보다 많음 (~ 수 MB)      
| L3 Cache | L2 Cache 보다 느림 |  L2 Cache 보다 많음 (~ 수십 MB)
| 주 메모리 | L3 Cache 보다 느림 |  L3 Cache 보다 많음 (수 GB ~)      


> 레지스터 (Register) 
> - CPU 내부에 있는 저장 공간으로 모든 CPU가 가지고 있습니다.
> - 레지스터의 억세스 속도는 기본적으로 CPU의 최대 연산 속도와 동일하다고 볼 수 있습니다.
> - 레지스터는 주 메모리처럼 일반적인 데이타 저장을 위해 있는 것이 아니라 
 CPU가 처리하는 모든 종류의 연산에 사용되는 데이타 값을 보관하는 Data Register류, 참조에 필요한 메모리 주소를 저장하는 Address Register류, 연산의 결과를 보관하기 위한 Arithmetic Register류 등이 있으며 SSE, AVX 등의 HW 기반 연산 가속 기능을 제공하는 경우에는 이와 관련된 전용 레지스터들이 추가적으로 있습니다.
 
> L1 Cache  
> - CPU 내부에 있는 저장 공간으로 (거의) 모든 CPU가 가지고 있습니다.
> - L1 Cache의 억세스 속도는 Register 보다는 느리지만 거의 CPU의 최대 연산 속도에 근접한다고 볼 수 있습니다. 

> - L1 Cache는 주 메모리에 저장된 바이너리 실행 코드를 캐싱하기 위한 I-Cache (Instruction Cache, Read Only) 와 실행 코드를 제외한 모든 데이타를 캐싱하기 위한 D-Cache (Data Cache, Read/Write)로 구분되어 있습니다.

> L2/L3 Cache
> - (현재는 대부분) CPU 내부에 있는 저장 공간으로 CPU에 따라 두가지 모두 있을수도 있고 한가지만 가지고 있을 수도 있습니다. 
> - L2/L3 Cache의 억세스 속도는 L2 가 L3 보다 빠르고 공간은 L3 가 L2 보다 많습니다. 
> - L2/L3 캐시는 L1 과는 다르게 I-Cache, D-Cache의 구분없이 CPU와 주 메모리 간의 Read/Write 에 대한 캐싱 기능을 제공합니다. 

> L1/L2/L3 Cache의 위치 
> - CPU의 내부 구조에 따라 틀리지만 인텔 Xeon 계열을 기준으로 설명한다면 
> - L1, L2 캐시는 CPU Chip 내부의 Core 별로 독립적으로 존재합니다. 
> - L3 캐시는 CPU Chip 단위로 존재합니다. 즉, 8 core CPU 라면 8개의 Core가 L3 캐시를 공유하며 이렇게 다수의 Core가 공유하는 캐시를 공유하는 경우 해당 Cache는 Last 라고도 부릅니다. 

Intel x86 게열 CPU (Xeon, i7,...) 를 기준으로 위의 구조를 간단하게 그림으로 표현하면 아래와 같이 표현할 수 있습니다. 
* Register : Hyper Thread 별로 1벌
* L1/L2 Cache : 각각의 Core별로 1벌 (Hyper Thread간에 공유) 
* L3 Cache : CPU 칩 별로 1벌 (Core간에 공유)  
* CPU가 2개인 2 소켓 보드면 ? QPI란 HW 로직을 통해 L3 Cache를 공유
* AMD x86, ARM등의 Cache 구조는 Intel 과 다름 

```
+-------------------------------------------------------+
|                       CPU Chip                        | 
|  +-----------------------------------+  +------+      |
|  |               Core                |  | Core |      |
|  | +--------------+ +--------------+ |  |      |      |
|  | | Hyper Thread | | Hyper Thread | |  |      |      |
|  | | +----------+ | | +----------+ | |  |      |      |
|  | | | Register | | | | Register | | |  |      |      |
|  | | +----------+ | | +----------+ | |  |      |      |
|  | +-------+------+ +------+-------+ |  |      | .... |
|  |         |               |         |  |      |      |
|  |    +----+---------------+----+    |  |      |      |
|  |    |        L1 Cache         |    |  |      |      |
|  |    +------------+------------+    |  |      |      |
|  |                 |                 |  |      |      |
|  +-----------------+-----------------+  +--+---+      |
|                    |                       |          |
|  +-----------------+-----------------+  +--+---+      |
|  |             L2 Cache              |  |  L2  |      |
|  +-----------------+-----------------+  +--+---+      |
|                    |                       |          |
|  +-----------------+-----------------------+--------+ |
|  |                    L3 Cahcel                     |<= QPI =>
|  +--------------------------------------------------+ |
+-------------------------------------------------------+
```

ATOMIC 연산의 필요성 
--------

위에서 보시다시피 CPU와 주 메모리 사이에는 Register를 포함하여 다수의  Cache 공간이 존재하며, SW에서 데이타를 읽거나 저장할 때 주 메모리와 CPU 사이에서 데이타에 대한 중간 경유지 역할을 수행하며 주 메모리의 입출력 성능 병목을 완화하는 기능을 수행합니다.

문제는 멀티쓰레드에서 다수의 쓰레드들이 여러개의 CPU Core에 분산되어 병렬로 동작하고 있는 상황에서는, 다수의 쓰레드가 특정 메모리 주소의 데이타에 대해 동일 시점 또는 매우 짧은 간격으로 읽거나 쓰려고 할 때 해당 주소에 있어야 할 최신의 데이타 값이 실제로는 Register, Cache, 주 메모리 중 어디에 있을 지 불분명하다는 점입니다. 

물론 모든 데이타를 주 메모리에 저장하는 방법도 있을 수 있지만 이는 전체적인 CPU의 성능을 심각하게 저하시키는 악영향을 주게 되므로 아래와 같은 관점에서 ATOMIC 연산을 사용하여 항상 데이타에 대한 최신값이 어느 쓰레드에서도 참조가 될 수 있도록 하게 됩니다.

* SW에서 접근하는 스택, 지역 변수, 공유/전역 변수등의 모든 데이타 중 실제 쓰레드간 공유가 필요한 데이타는 공유/전역 변수의 일부분임
* 대규모의 데이타 참조가 필요한 경우에는 락을 이용하여 해결이 가능
* 소량의 데이타들에 대해서 락을 사용하기에는 락의 오버헤드가 큼 

좀 더 이해를 돕기 위해 몇가지 예를 좀 들어보도록 하겠습니다. 


### Register에 의한 데이타 참조 오류

SW에서 아래와 같이 단순한 기능을 수행하는 코드가 실제 CPU에서 어떻게 수행되는 지 알아보도록 하겠습니다. 

```cpp
int value;      // 전역 변수
int my_func() {
    value += 1;
    return value;
}

```
위의 함수를 컴파일한 후 CPU에서 실제 수행하는 어셈블러 코드로 역변환(Disassembly)을 하면 아래와 같은 어셈블러 코드가 생성됩니다.


```cpp
int my_func()
{
  push   rbp
  mov    rbp,rsp                        // 스택 정리 
    value += 1;
  mov    eax,DWORD PTR [rip+0x200b54]   // #1, value를 eax 레지스터로 복사 
  add    eax,0x1                        // #2, eax 레지스터의 값을 증가
  mov    DWORD PTR [rip+0x200b4b],eax   // #3, eax 레지스터 값을 메모리로 복사 
  
    return value;
  mov    eax,DWORD PTR [rip+0x200b45]   // 메모리 값을 레지스터로 복사
}
  pop    rbp
  ret

```

위의 소스에서 C 코드로 표현된 부분의 아래쪽에 위치한 어셈블러가 해당 C 코드에 대한 어셈블러 코드라고 보면 되고, *"value += 1"* 을 수행하기 위해 *"#1 ~ #3*" 까지의 세개의 어셈블리 코드가 수행됨을 알 수 있습니다. 코드 옆에 주석을 달아놓은 것처럼 하나의 변수를 중가하기 위해 CPU는 데이타가 있는 위치의 메모리에서 데이타를 CPU 내부의 레지스터로 가져온 다음 값을 증가시키는 연산을 수행한 다음 결과값을 다시 메모리로 저장힙니다.

* CPU는 단순한 메모리의 읽기 및 복사가 아닌 사칙연산, 비교 (+/- 연산에 해당하므로) 를 포함한 모든 수학적인 연산은 레지스터를 이용해야 합니다 - 잘 생각해보면 메모리는 단순한 저장장치일 뿐이므로 연산을 수행할 수 없는 게 당연합니다.

위 코드가 멀티쓰레드에서 발생시키는 문제는 _value_ 가 전역변수이므로 모든 쓰레드가 접근을 할 수 있으며, CPU 역시 다수의 Core와 각각의 독립적인 Register를 가지고 있으므로 만약 4개의 Core가 동시에 *"value = 0"* 에 대해 *"value += 1"* 절차를 수행한다면 4번의 연산이 수행되므로 *"value +=4"* 가 되면 좋겠지만 *"#1 ~ #3*" 과정이 동시에 수행되고 *#2* 에서 Register는 모두 0이라는 값을 가지고 덧셈을 수행하므로 결론적으로 *"value += 1"* 인 결과가 나타납니다.

물론 위의 상황외에도 A라는 쓰레드가 #2를 실행중인데 B 라는 쓰레드가 #1을 수행하는 경우, A는 #3를 수행하는 데 B는 #1 또는 #2를 수행하는 경우 등 더 많은 상황이 있을 수 있으므로 **안전하게** 덧셈을 할 수 있는 방법이 필요합니다. 


### Cache에 의한 데이타 참조 오류

Register에 의한 발생하는 문제를 어떻게 해결하는지를 알아보기 전에  Cache에 의해 발생하는 문제를 먼저 알아보도록 하겠습니다.

앞서 설멍한 것처럼 Cache는 Core, CPU단위로 계층적인 구조로 만들어져 있으며, 주 메모리와 CPU (정확히는 Register) 사이에 위치합니다. 

Cache는 별도의 주소를 가지지 않고 주 메모리의 내용을 투영하기 때문에  소프트웨어에서 직접적으로 컨트롤을 할 수 없다고 볼 수 있습니다 

* Cache 메모리는 주 메모리 대비 빠른 접근 속도 때문에 소프트웨어에서 Cache 영역의 일부 또는 전부를 직접 제어할 수 있도록 CPU의 HW 구조 설계가 되어 있는 경우 SW에 의해 제어되는 Cache 메모리 영역을 Scratchpad 메모리라고 부릅니다. 
* Scratchpad 메모리는 일부 CPU 들에서 각각의 HW의 특징에 따라 제공되며 일반적인 응용 계층의 SW에서 사용하기는 상당히 어렵다고 할 수 있습니다. 









참고 
---------

> C 소스 컴파일하는 방법 : gcc -g -o sample sample.c 
> - -g : 실행파일내에 디버깅 정보를 추가합니다. 이 정보를 이용하여  Disassembly 시 어셈블리 코드내에 C 코드 참조 위치를 표시할 수 있습니다. 
> - -o : 컴파일된 실행 파일명을 지정합니다. 위 예에서는 *sample*이 실행파일입니다.
> - -Ox 계열의 최적화 옵션을 주게 되면 최적화로 인해 C 코드 참조 위치가 부정확하게 나옵니다. 
 

> Disassembly 생성 방법 : objdump -S -d -M intel-Mnemonic out 
> - -S : 생성된 어셈블러 코드내에 참조용 원본 C 코드를 추가합니다. 단 확장자를 제외한 실행파일명과 소스 파일명이 같아야 합니다.  
> - -d :objdump 프로그램에게 Disassembly 를 요청합니다.  
> - -M intel-Mnemonic : 어셈블러 코드를 인텔 어셈블러 형태로 출력합니다. 


Links 
---------

* https://en.wikipedia.org/wiki/CPU_cache
* https://en.wikipedia.org/wiki/Scratchpad_memory
* https://www.nextplatform.com/2016/05/31/intel-lines-thunderx-arms-xeons/
